{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "55129ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from PIL import Image "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65cc1f1",
   "metadata": {},
   "source": [
    "# 1. Read in the training/testing data, transform them into pixelation vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7bb8f290",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read the list for training/testing data points: \n",
    "f_train = open('downgesture_train.list','r')\n",
    "f_test = open('downgesture_test.list','r')\n",
    "line_train = f_train.readlines()\n",
    "line_test  = f_test.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "26b3aed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lists for storing training data/testing data:\n",
    "training = []\n",
    "testing = []\n",
    "#Lists for storing labels of training/testing data\n",
    "training_label = []\n",
    "testing_label = []\n",
    "\n",
    "#Store the training data to list 'training' with pixelation\n",
    "for i in line_train:\n",
    "    im_i = np.asarray(Image.open('C:/Users/User/Desktop/Machine Learning HW 5/'+(i.rstrip('\\n'))))\n",
    "    training.append(im_i)\n",
    "    \n",
    "#Storing the labels of respective data poins in the training set     \n",
    "    if 'down' in i:\n",
    "        training_label.append([1])\n",
    "    else:\n",
    "        training_label.append([0])\n",
    "\n",
    "#Store the testing data to list 'testing' with pixelation\n",
    "for j in line_test:\n",
    "    im_j = np.asarray(Image.open('C:/Users/User/Desktop/Machine Learning HW 5/'+(j.rstrip('\\n'))))\n",
    "    testing.append(im_j)\n",
    "    \n",
    "#Storing the labels of respective data poins in the testing set       \n",
    "    if 'down' in j:\n",
    "        testing_label.append([1])\n",
    "    else:\n",
    "        testing_label.append([0])\n",
    "    \n",
    "f_train.close()\n",
    "f_test.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8e8aeb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reshape each image's pixel data to a 960 x 1 vector\n",
    "for i in range(len(testing)):\n",
    "    testing[i]=testing[i].reshape(960,1)\n",
    "    \n",
    "for j in range(len(training)):\n",
    "    training[j]=training[j].reshape(960,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "1a948abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the data:\n",
    "#len(training)\n",
    "#len(testing)\n",
    "#training[5]\n",
    "#training[5].size\n",
    "#testing[10]\n",
    "#testing[10].size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca742d10",
   "metadata": {},
   "source": [
    "# Define the neural networks model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "18316b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class neural_networks(object):\n",
    "    \n",
    "#Randomize the initial weights and bias:     \n",
    "    def __init__(self,structure): #structure = a list containing the number of neurons in each layer \n",
    "        self.structure = structure\n",
    "        self.weight=[]\n",
    "        self.bias=[]\n",
    "        self.delta_weight = []\n",
    "        self.delta_bias = []\n",
    "        self.length = len(structure)\n",
    "                \n",
    "        for i,j in zip(self.structure[:-1],self.structure[1:]):\n",
    "            (self.weight).append(np.random.uniform(-0.01,0.01,size=(j,i)))   \n",
    "            #Here, self.weights[i] stores the weights connecting the i+1 and i+2 layer of networks \n",
    "\n",
    "            \n",
    "        for i in structure[1:]:\n",
    "            (self.bias).append(np.random.randn(i,1))\n",
    "            #Here, self.bias[i] stores the biases in the i+1 layer of networks (exclude the input layer)\n",
    "            \n",
    "            \n",
    "        for i,j in zip(self.structure[:-1],self.structure[1:]):\n",
    "            (self.delta_weight).append(np.zeros((j,i)))   \n",
    "          \n",
    "            \n",
    "        for i in structure[1:]:\n",
    "            (self.delta_bias).append(np.zeros((i,1)))\n",
    "\n",
    "#Define the sigmoid function:\n",
    "    def sigmoid(self,s): \n",
    "        sig = 1/(1 + np.exp(-s))\n",
    "        return sig \n",
    "\n",
    "#Define the function for sigmoid function's derivative:    \n",
    "    def del_sigmoid(self,s):\n",
    "        del_sig = self.sigmoid(s)*(1-self.sigmoid(s))\n",
    "        return del_sig\n",
    "    \n",
    "#Forward process:\n",
    "    def feedforward (self,x):\n",
    "        \n",
    "        self.zs=[]   \n",
    "        self.activations=[]\n",
    "        for i in range(self.length-1):\n",
    "            self.zs.append([])           #A list for containing w*x + b among different layers \n",
    "            self.activations.append([])  #A list for containing  all activation functions among different layers\n",
    "            \n",
    "        self.activations.insert(0,x)     #Add the input variable to the first column of activations list, for later computation usage\n",
    "       \n",
    "    \n",
    "       #Calculate the activation functions among respective layers: \n",
    "        n=0    \n",
    "        while n < (self.length-1):\n",
    "        \n",
    "            for w,b in zip(self.weight[n],self.bias[n]):\n",
    "                z = np.dot(w,x)+b \n",
    "                self.zs[n].append(z)\n",
    "                self.activations[n+1] = list(map(self.sigmoid,self.zs[n]))\n",
    "            x = self.zs[n] \n",
    "            n=n+1     \n",
    "\n",
    "            \n",
    "#Backward process:\n",
    "    def backpropagation(self,desired_output):\n",
    "        \n",
    "        #del c/del a :\n",
    "        del_cost = [[2*(desired_output[i]-self.activations[-1][i]) for i in range(self.structure[-1])]] \n",
    "        #(del c/del a)       \n",
    "        #(del a/del z):\n",
    "        del_cost_sigmoid = [self.del_sigmoid(self.zs[-1][i]) for i in range(len(self.zs[-1]))]\n",
    "        \n",
    "        delta = [(del_cost[i] * del_cost_sigmoid[i]) for i in range(len(del_cost))]  \n",
    "        self.delta_bias[-1] = delta\n",
    "        self.delta_weight[-1] = np.dot(delta,np.array(self.activations[-2]).T)\n",
    "        \n",
    "        \n",
    "        #Aftering computing the gradients of hidden layers-output layers, next, calculate the gradients in the remaining layers:\n",
    "        for layer in range(2,self.length):\n",
    "            \n",
    "            self.da_dz = list(map(self.del_sigmoid,self.zs[-layer]))\n",
    "            delta = [(np.dot(np.array(self.weight[-layer+1]).T,delta))[i]*self.da_dz[i] for i in range(len(self.da_dz))]\n",
    "            self.delta_bias[-layer] = delta\n",
    "            self.delta_weight[-layer] = np.dot(delta,np.array(self.activations[-layer-1]).T)\n",
    "        \n",
    "        return self.delta_bias,self.delta_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ac5f58",
   "metadata": {},
   "source": [
    "# Train the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "74f030c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = neural_networks([960,100,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "f08e0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_sum = [[0]*100,[0]*1]         #A list for storing the sum of bias gradients after training through each data point \n",
    "w_sum = [[[0]*960]*100,[[0]*100]*1]  #A list for storing the sum of weight gradients training through each data point\n",
    "\n",
    "for _ in range(1000):           #Updating the gradients with 1000 iterations \n",
    "    for x,y in zip(training,training_label):\n",
    "        model.feedforward(x)\n",
    "        bn,wn = model.backpropagation(y)\n",
    "    \n",
    "    #The following four for loops calculate the sum of gradients among 184 training data points\n",
    "        for bias_layer1 in range(100):\n",
    "            b_sum[0][bias_layer1] = b_sum[0][bias_layer1]+bn[0][bias_layer1]\n",
    "    \n",
    "        for bias_layer2 in range(1):\n",
    "            b_sum[1][bias_layer2] = b_sum[1][bias_layer2]+bn[1][0][bias_layer2]\n",
    "    \n",
    "        for neural_1 in range(100):\n",
    "            for w_layer1 in range(960):\n",
    "                w_sum[0][neural_1][w_layer1] = w_sum[0][neural_1][w_layer1]+wn[0][neural_1][0][w_layer1]\n",
    "    \n",
    "        for neural_2 in range(1):\n",
    "            for w_layer2 in range(100):\n",
    "                w_sum[1][neural_2][w_layer2] = w_sum[1][neural_2][w_layer2]+wn[1][0][neural_2][w_layer2]\n",
    "   \n",
    "   #Next, implement the gradient descend,updating the weights/biases with learning rate 0.1 \n",
    "    for i in range(100):\n",
    "        model.bias[0][i] = model.bias[0][i] - (0.1*((b_sum[0][i])/184))\n",
    "\n",
    "    for j in range(1):\n",
    "        model.bias[1][j] = model.bias[1][j] - (0.1*((b_sum[1][j])/184))\n",
    "\n",
    "    for k in range(100):\n",
    "        for l in range(960):\n",
    "            model.weight[0][k][l] = model.weight[0][k][l] - (0.1*((wn[0][k][0][l])/184))\n",
    "        \n",
    "    for m in range(1):\n",
    "        for n in range(100):\n",
    "            model.weight[1][m][n] = model.weight[1][m][n] - (0.1*((wn[1][0][m][n])/184))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d60411",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "bcdc5118",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing \n",
    "\n",
    "prediction = []\n",
    "accurate_count = 0 \n",
    "\n",
    "for x,y in zip(testing,testing_label):\n",
    "    model.feedforward (x)\n",
    "    if model.activations[-1][0][0] >= 0.5:\n",
    "        prediction.append(1)\n",
    "        if y[0] == 1:\n",
    "            accurate_count += 1\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    elif model.activations[-1][0][0] < 0.5:\n",
    "        prediction.append(0)\n",
    "        if y[0] == 0:\n",
    "            accurate_count +=1\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "291fb7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.reshape  #Print the prediction result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "3512a356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7831325301204819\n"
     ]
    }
   ],
   "source": [
    "accuracy = accurate_count/len(testing)  #accuracy rate \n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
